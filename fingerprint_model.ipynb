{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fingerprint_model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHzHdrSKJQQi"
      },
      "source": [
        "# %reset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqYtCZWNJU5k",
        "outputId": "f176a437-5382-4d15-8db3-34a68404098b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "zhhfhN6MJQQq"
      },
      "source": [
        "<h2>Pre Process Dataset</h2>\n",
        "<h6>get dataset</br>\n",
        "split train and test data</br>\n",
        "spilt every matrix song to one second segment</br></h6>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMHMPubbJQQu"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "DATASET_PATH = \"./drive/MyDrive/chromagram_dataset/all.npy\"\n",
        "DATASET_TRAIN = \"./drive/MyDrive/chromagram_dataset/train.npy\"\n",
        "DATASET_TEST = \"./drive/MyDrive/chromagram_dataset/test.npy\"\n",
        "saved_data = os.path.exists(DATASET_TRAIN) and os.path.exists(DATASET_TEST)\n",
        "if not saved_data:\n",
        "  with open(DATASET_PATH, 'rb') as f:\n",
        "      data = np.load(f, allow_pickle=True)\n",
        "  data.shape"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEqsSDOBJQQz"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "if not saved_data:\n",
        "  data_train, data_test, _, _ = train_test_split(data, data, test_size=0.2, random_state=42)\n",
        "  del data\n",
        "  data_train.shape, data_test.shape, data_train[0].shape"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFVGucxlJQQ2"
      },
      "source": [
        "import librosa\n",
        "import tensorflow as tf"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wy5Q5xppJQQ4"
      },
      "source": [
        "sample_rate = 16000\n",
        "hop_length = int(sample_rate * 0.1)\n",
        "n_fft = int(sample_rate * 0.2)\n",
        "DIFF = 1\n",
        "allowed_duration = 10000\n",
        "special_value = -10\n",
        "frame_sec_indexes = [librosa.time_to_frames(i, sample_rate, n_fft=n_fft, hop_length=hop_length)\n",
        "                     for i in range(1, allowed_duration, DIFF)]\n",
        "\n",
        "max_frames_in_diff=max([frame_sec_indexes[i+1] - frame_sec_indexes[i] for i in range(len(frame_sec_indexes)-1)])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRjeg7dmJQQ6"
      },
      "source": [
        "def clean_frame_matrix(feature: np.array):\n",
        "    # add padding\n",
        "    if 0 in feature.shape:\n",
        "      print('here')\n",
        "    full_matrix = np.full((max_frames_in_diff, 12), special_value, dtype=np.float32)\n",
        "    full_matrix[:feature.shape[0], :feature.shape[1]] = feature\n",
        "\n",
        "    return full_matrix\n",
        "\n",
        "def split_features(features):\n",
        "\n",
        "    split_features = np.empty((0, 10, 12))\n",
        "    # song_indexes = dict()\n",
        "    for i in range(len(features)):\n",
        "        # pre_len = len(split_features)\n",
        "        split_feature = np.split(features[i], [each for each in frame_sec_indexes if each < len(features[i])])\n",
        "        split_features = np.append(split_features, np.array([clean_frame_matrix(each) for each in split_feature]),\n",
        "                                   axis=0)\n",
        "        print(f'\\r{i} done', end='\\r')\n",
        "\n",
        "        # add data to song_indexes {song3: (start_index, end_index), }\n",
        "        # song_indexes[i] = (pre_len, len(split_features))\n",
        "\n",
        "    return split_features\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NpXe1THJQQ_"
      },
      "source": [
        "if not saved_data:\n",
        "  data_train = split_features(data_train)\n",
        "  with open(DATASET_TRAIN, 'wb') as f:\n",
        "    np.save(f, data_train)\n",
        "  print(data_train.shape)\n",
        "else: \n",
        "  with open(DATASET_TRAIN, 'rb') as f:\n",
        "      data_train = np.load(f, allow_pickle=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8wUHiigJQRC"
      },
      "source": [
        "if not saved_data:\n",
        "  data_test = split_features(data_test)\n",
        "  with open(DATASET_TEST, 'wb') as f:\n",
        "    np.save(f, data_test)\n",
        "  print(data_test.shape)\n",
        "else: \n",
        "  with open(DATASET_TEST, 'rb') as f:\n",
        "      data_test = np.load(f, allow_pickle=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "_2VwFLKiJQRJ"
      },
      "source": [
        "<h2>seq2seq model</h2>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjmFv_k2ZZQ8"
      },
      "source": [
        "from keras.layers import LSTM, GRU, Dense, Input, RepeatVector, TimeDistributed, Masking, Activation\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "\n",
        "# for recreate model\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "def binary_activation(x):\n",
        "  return K.cast(K.greater(x, 0), K.floatx())\n",
        "\n",
        "get_custom_objects().update({'binary_activation': Activation(binary_activation)})\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDxYEHg9JQRK"
      },
      "source": [
        "\n",
        "# encoder layers\n",
        "encoder_inputs = Input(shape=(max_frames_in_diff, 12))\n",
        "masking = Masking(mask_value=special_value)(encoder_inputs)\n",
        "encoder_lstm = LSTM(64, return_state=True, return_sequences=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(masking)\n",
        "encoder_lstm2 = LSTM(24, return_state=True)\n",
        "encoder_outputs2, state_h2, state_c2 = encoder_lstm2(encoder_outputs)\n",
        "activation_layer = Activation(binary_activation)\n",
        "encoder_outputs2 = activation_layer(encoder_outputs2)\n",
        "encoder_states = [state_h, state_c]\n",
        "encoder_states2 = [state_h2, state_c2]\n",
        "\n",
        "# decoder input\n",
        "decoder_inputs = RepeatVector(max_frames_in_diff)(encoder_outputs2)\n",
        "\n",
        "# decoder layers\n",
        "decoder_lstm = LSTM(24, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states2)\n",
        "decoder_lstm2 = LSTM(64, return_sequences=True, return_state=True)\n",
        "decoder_outputs2, _, _ = decoder_lstm2(decoder_outputs, initial_state=encoder_states)\n",
        "decoder_time = TimeDistributed(Dense(12, activation='softmax'))\n",
        "decoder_outputs2 = decoder_time(decoder_outputs2)\n",
        "\n",
        "# define model\n",
        "model = Model(encoder_inputs, decoder_outputs2)\n",
        "\n",
        "# define encoder model\n",
        "encoder_model = Model(encoder_inputs, encoder_outputs2)\n",
        "\n",
        "# define inference decoder\n",
        "decoder_state_input_h, decoder_state_input_c = Input(shape=(64,)), Input(shape=(64,))\n",
        "decoder_state_input_h2, decoder_state_input_c2 = Input(shape=(24,)), Input(shape=(24,))\n",
        "decoder_inputs_layer = Input(shape=(10, 24))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c, \n",
        "                         decoder_state_input_h2, decoder_state_input_c2]\n",
        "decoder_outputs, state_h, state_c = decoder_lstm2(decoder_inputs_layer, initial_state=decoder_states_inputs[:2])\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_time(decoder_outputs)\n",
        "decoder_model = Model([decoder_inputs_layer] + decoder_states_inputs, [decoder_outputs] + decoder_states)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_4W-eA0JQRM",
        "outputId": "f83b55ab-0c94-44bd-db84-aeaf765db1d0"
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.Huber(), metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_15 (InputLayer)           [(None, 10, 12)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "masking_3 (Masking)             (None, 10, 12)       0           input_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_11 (LSTM)                  [(None, 10, 64), (No 19712       masking_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_12 (LSTM)                  [(None, 24), (None,  8544        lstm_11[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 24)           0           lstm_12[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "repeat_vector_3 (RepeatVector)  (None, 10, 24)       0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lstm_13 (LSTM)                  [(None, 10, 24), (No 4704        repeat_vector_3[0][0]            \n",
            "                                                                 lstm_12[0][1]                    \n",
            "                                                                 lstm_12[0][2]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_14 (LSTM)                  [(None, 10, 64), (No 22784       lstm_13[0][0]                    \n",
            "                                                                 lstm_11[0][1]                    \n",
            "                                                                 lstm_11[0][2]                    \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_1 (TimeDistrib (None, 10, 12)       780         lstm_14[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 56,524\n",
            "Trainable params: 56,524\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SB90DzKKJQRO",
        "outputId": "971b9794-eb8b-4097-9f71-acf5e9e098ae"
      },
      "source": [
        "model.fit(data_train, data_train, epochs=10, validation_split=0.2, workers=5)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60385/60385 [==============================] - 1791s 30ms/step - loss: 0.0792 - accuracy: 0.8314 - val_loss: 0.0777 - val_accuracy: 0.8844\n",
            "Epoch 2/10\n",
            "60385/60385 [==============================] - 1756s 29ms/step - loss: 0.0777 - accuracy: 0.8959 - val_loss: 0.0773 - val_accuracy: 0.9080\n",
            "Epoch 3/10\n",
            "60385/60385 [==============================] - 1698s 28ms/step - loss: 0.0775 - accuracy: 0.9128 - val_loss: 0.0772 - val_accuracy: 0.9187\n",
            "Epoch 4/10\n",
            "60385/60385 [==============================] - 1702s 28ms/step - loss: 0.0774 - accuracy: 0.9199 - val_loss: 0.0771 - val_accuracy: 0.9236\n",
            "Epoch 5/10\n",
            "60385/60385 [==============================] - 1679s 28ms/step - loss: 0.0773 - accuracy: 0.9246 - val_loss: 0.0771 - val_accuracy: 0.9282\n",
            "Epoch 6/10\n",
            "60385/60385 [==============================] - 1689s 28ms/step - loss: 0.0773 - accuracy: 0.9284 - val_loss: 0.0770 - val_accuracy: 0.9311\n",
            "Epoch 7/10\n",
            "60385/60385 [==============================] - 1674s 28ms/step - loss: 0.0773 - accuracy: 0.9314 - val_loss: 0.0770 - val_accuracy: 0.9362\n",
            "Epoch 8/10\n",
            "60385/60385 [==============================] - 1658s 27ms/step - loss: 0.0772 - accuracy: 0.9338 - val_loss: 0.0770 - val_accuracy: 0.9376\n",
            "Epoch 9/10\n",
            "60385/60385 [==============================] - 1641s 27ms/step - loss: 0.0772 - accuracy: 0.9356 - val_loss: 0.0770 - val_accuracy: 0.9391\n",
            "Epoch 10/10\n",
            "60385/60385 [==============================] - 1667s 28ms/step - loss: 0.0772 - accuracy: 0.9371 - val_loss: 0.0770 - val_accuracy: 0.9406\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdcbeaca050>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "141Fvc4DaTPT",
        "outputId": "f88bd442-4af2-4bd3-cdf7-36cbb6e015a0"
      },
      "source": [
        "model.evaluate(data_test, data_test)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19223/19223 [==============================] - 144s 7ms/step - loss: 0.0775 - accuracy: 0.9395\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07751147449016571, 0.9395154714584351]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hf0ws5dvimZa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd768667-43c4-4429-caf0-de77252957a0"
      },
      "source": [
        "result=encoder_model.predict(data_test[1001:1002])[0]\n",
        "result.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hnOkAVI-gcK",
        "outputId": "6371d6d9-c689-4505-e9c8-3ee0f6c24c63"
      },
      "source": [
        "result"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
              "       1., 1., 0., 0., 0., 0., 1.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLUOs4RwYipc"
      },
      "source": [
        "# save model\n",
        "model_json = model.to_json()\n",
        "with open(\"./drive/MyDrive/fingerprint_model/fingerprint_model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"./drive/MyDrive/fingerprint_model/fingerprint_model.h5\")\n",
        "\n",
        "# save encoder and decoder\n",
        "encoder_json = encoder_model.to_json()\n",
        "with open(\"./drive/MyDrive/fingerprint_model/encoder_model.json\", \"w\") as json_file:\n",
        "    json_file.write(encoder_json)\n",
        "encoder_model.save_weights(\"./drive/MyDrive/fingerprint_model/encoder_model.h5\")\n",
        "\n",
        "decoder_json = decoder_model.to_json()\n",
        "with open(\"./drive/MyDrive/fingerprint_model/decoder_model.json\", \"w\") as json_file:\n",
        "    json_file.write(decoder_json)\n",
        "decoder_model.save_weights(\"./drive/MyDrive/fingerprint_model/decoder_model.h5\")"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VpSTJS8A-lW",
        "outputId": "7253cc7e-920f-4b5f-dc41-b3684d685b8c"
      },
      "source": [
        "# load encoder\n",
        "from keras.models import model_from_json\n",
        "json_file = open('./drive/MyDrive/fingerprint_model/encoder_model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json, \n",
        "                               {'binary_activation': Activation(binary_activation)})\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"./drive/MyDrive/fingerprint_model/encoder_model.h5\")\n",
        "print(\"Loaded model from disk\")\n",
        "loaded_model.predict(data_test[1001:10002])[0]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded model from disk\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
              "       1., 1., 0., 0., 0., 0., 1.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    }
  ]
}