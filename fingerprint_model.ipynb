{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<h2>Pre Process Dataset</h2>\n",
    "<h6>get dataset</br>\n",
    "split train and test data</br>\n",
    "spilt every matrix song to one second segment</br></h6>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "(13281,)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "DATASET_PATH = \"./all.npy\"\n",
    "with open(DATASET_PATH, 'rb') as f:\n",
    "    data = np.load(f, allow_pickle=True)\n",
    "data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "((10624,), (2657,), (1995, 12))"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train, data_test, _, _ = train_test_split(data, data, test_size=0.2, random_state=42)\n",
    "data_train.shape, data_test.shape, data_train[0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "import librosa\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "99989"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_rate = 16000\n",
    "hop_length = int(sample_rate * 0.1)\n",
    "n_fft = int(sample_rate * 0.2)\n",
    "DIFF = 1\n",
    "allowed_duration = 10000\n",
    "frame_sec_indexes = [0, ] + [librosa.time_to_frames(i, sample_rate, n_fft=n_fft, hop_length=hop_length)\n",
    "                             for i in range(1, allowed_duration, DIFF)]\n",
    "frame_sec_indexes[-1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "def split_features(features):\n",
    "\n",
    "    split_features = list()\n",
    "    song_indexes = dict()\n",
    "    for i in range(len(features)):\n",
    "        pre_len = len(split_features)\n",
    "        if (len(features[i])) > frame_sec_indexes[-1]:\n",
    "            print(len(features[i]), i)\n",
    "        split_feature_i = [features[i][frame_sec_indexes[index]: frame_sec_indexes[index+1]]\n",
    "                           for index in range(len(frame_sec_indexes)-1)\n",
    "                           if frame_sec_indexes[index] < len(features[i])]\n",
    "        # add data to split_feature\n",
    "        split_features += split_feature_i\n",
    "\n",
    "        # add data to song_indexes {song3: (start_index, end_index), }\n",
    "        song_indexes[i] = (pre_len, len(split_features))\n",
    "\n",
    "    return np.array(split_features), song_indexes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MJSH\\AppData\\Local\\Temp/ipykernel_14264/860082388.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array(split_features), song_indexes\n"
     ]
    },
    {
     "data": {
      "text/plain": "((2415387,), (615124,))"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_train_data, train_song_indexes = split_features(data_train)\n",
    "final_test_data, test_song_indexes = split_features(data_test)\n",
    "final_train_data.shape, final_test_data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>seq2seq model</h2>\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "from keras.layers import LSTM, GRU, Dense, Input, RepeatVector, TimeDistributed\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "encoder_inputs = Input(shape=(None, 12))\n",
    "encoder = LSTM(128, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]\n",
    "# define training decoder\n",
    "decoder_inputs = RepeatVector(12)(encoder_outputs)\n",
    "\n",
    "# decoder_inputs = Input(shape=(None, 12))\n",
    "decoder_lstm = LSTM(128, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_time = TimeDistributed(Dense(12, activation='softmax'))\n",
    "decoder_outputs = decoder_time(decoder_outputs)\n",
    "model = Model(encoder_inputs, decoder_outputs)\n",
    "# define inference encoder\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# define inference decoder\n",
    "decoder_state_input_h = Input(shape=(128,))\n",
    "decoder_state_input_c = Input(shape=(128,))\n",
    "decoder_inputs_layer = Input(shape=(12, 128))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs_layer, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_time(decoder_outputs)\n",
    "decoder_model = Model([decoder_inputs_layer] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}